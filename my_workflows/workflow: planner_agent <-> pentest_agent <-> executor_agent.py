import autogen
import os

from agents.for_group_chat.executor_agents import ExecutorAgent, ExecuteInDocker
from agents.for_group_chat.planner_agents import PlannerAgent
from utils.groupchat_utils import registration_tools_in_agents

config_list = autogen.config_list_from_json(
    "../OAI_CONFIG_LIST",
    file_location=os.getcwd(),
    filter_dict={
        "model": ["gpt-4", "gpt-4-0314", "gpt4", "gpt-4-32k", "gpt-4-32k-0314", "gpt-4-32k-v0314",
                  "gpt-4-turbo-2024-04-09"],
    }
)

llm_config_planner = {"config_list": config_list, "cache_seed": 8888}
llm_config_pentest = {"config_list": config_list, "cache_seed": 88888}
llm_config_manager = {"config_list": config_list, "cache_seed": 888888}
PLANNER_PROMPTS = (
    "GOALS: Design and orchestrate a comprehensive penetration testing strategy utilizing the "
    "specialized tools available through your suite of agents."
    "REQUIRED DATA COLLECTION FROM AGENT NETWORK:"
    "   1. List of Penetration Testing Tools in the Format <id_tools> : <tool_name> : <description>."
    "INSTRUCTIONS:"
    "   inst. 1: Get all data according 'Required Data Collection from Agent Network';"
    "   inst. 2: Create pentest plane based on got data."
)
PENTEST_PROMPTS = (
    "GOALS: Make a pentest according getting instruction from planner_agent."
    "INSTRUCTIONS:"
    "   inst. 1: Provide requested information by planner_agent;"
    "   inst. 2: Analyze the task received from the planner agent and select the most suitable tool for its execution;"
    "   inst. 3: Send the code from the tool with the input data filled in to the chat manager for execution;"
    "   inst. 4: When all planner executed will be executed, all result send to planner_agent!"

)



planner_agent = PlannerAgent(
    llm_config=llm_config_planner,
    system_message=PLANNER_PROMPTS
)

init_agent = autogen.UserProxyAgent(
    name="init_agent",
    human_input_mode="NEVER"
)

pentest_agent = autogen.AssistantAgent(
    name="pentest_agent",
    description="Perform a pentest!",
    llm_config=llm_config_pentest,
    system_message=PENTEST_PROMPTS
)


execute_in_docker = ExecuteInDocker(image="nmap_python_image:latest", container_name="python_with_nmap_container")
executor_agent = ExecutorAgent(code_execution_config={"executor": execute_in_docker})

registration_tools_in_agents(pentest_agent, "register_for_llm", "pentest_tools")
registration_tools_in_agents(executor_agent, "register_for_execution", "pentest_tools")

graph_dict = {init_agent: [planner_agent], planner_agent: [pentest_agent],
              pentest_agent: [executor_agent, planner_agent], executor_agent: [pentest_agent]}

group_chat = autogen.GroupChat(
    agents=[planner_agent, init_agent, pentest_agent, executor_agent],
    messages=[],
    max_round=20,
    speaker_selection_method="auto",
    allowed_or_disallowed_speaker_transitions=graph_dict,
    allow_repeat_speaker=None,
    speaker_transitions_type="allowed"
)

chat_manager = autogen.GroupChatManager(
    groupchat=group_chat,
    llm_config=llm_config_manager
)

init_agent.initiate_chat(chat_manager, message="create pentest plan for scan 127.0.0.1")
